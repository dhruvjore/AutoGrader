# ğŸ“š AutoGrader â€“ AI-Powered Assignment Grading

AutoGrader is a **Streamlit-based AI application** that grades assignments, exam papers, and submissions automatically using **LLM-powered evaluation + rubrics + answer keys**.  
It supports multiple file types (PDFs, text, JSON rubrics), generates **percentage-based grades**, and produces **detailed markdown/PDF reports** for instructors.

---

## âœ¨ Features

- ğŸ” **Rubric-Driven Grading**  
  Upload rubrics (criteria, weightages, answer keys) and grade assignments fairly.  
- ğŸ“Š **Percentage-Based Evaluation**  
  Works for assignments of any maximum marks â€” grading normalized to 100%.  
- ğŸ§  **LLM-Powered Feedback**  
  Uses Gemini / Groq / Prometheus models for AI-assisted grading & evidence generation.  
- ğŸ“‘ **Beautiful Reports**  
  Exports **Markdown reports** (and optionally PDF) with student name, score, grade, and evidence.  
- ğŸ“‚ **Organized Storage**  
  - `data/reports/` â†’ Final reports  
  - `data/graded_copies/` â†’ Graded student submissions  
  - `data/submissions/` â†’ Uploaded submissions  
  - `data/knowledge/` â†’ Rubrics, questions, and reference material  
- âš¡ **Streamlit UI**  
  Easy drag-and-drop interface for faculty to upload rubrics & assignments.

---

## ğŸš€ Quick Start

### 1. Clone the Repo
```bash
git clone https://github.com/dhruvjore/AutoGrader.git
cd AutoGrader
```

### 2. Setup Environment
```bash
python -m venv autograder_venv
.\autograder_venv\Scripts\activate   # Windows
# or
source autograder_venv/bin/activate  # Mac/Linux
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the App
```bash
streamlit run app.py
```

---

## ğŸ—ï¸ Project Structure

```
AutoGrader/
â”‚â”€â”€ app.py                  # Streamlit main app
â”‚â”€â”€ grader.py               # Core grading pipeline
â”‚â”€â”€ requirements.txt        # Python dependencies
â”‚â”€â”€ .gitignore              # Ignored files & folders
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ submissions/        # Student uploads
â”‚   â”œâ”€â”€ graded_copies/      # Annotated student copies
â”‚   â”œâ”€â”€ reports/            # Generated reports
â”‚   â””â”€â”€ knowledge/          # Rubrics & reference docs
â”‚â”€â”€ src/
    â”œâ”€â”€ grader/             # Grade evaluator, models
    â”œâ”€â”€ reporting.py        # Markdown/PDF report generator
    â””â”€â”€ llm/                # Gemini/Groq client
```

---

## âš™ï¸ Configuration

Project settings are stored in `.env`:

```env
DOCS_DIR=data/knowledge
CHUNK_SIZE=1200
CHUNK_OVERLAP=200
TOP_K=6
LLM_PROVIDER=gemini
OPENAI_COMPAT_BASE_URL=...
OPENAI_COMPAT_API_KEY=...
OPENAI_COMPAT_MODEL=gemma-7b-it
```

---

## ğŸ“ˆ Example Workflow

1. Instructor uploads `rubric.json` and `student_submissions.pdf`
2. AutoGrader parses submissions & rubrics
3. AI evaluator assigns percentage + letter grade (A+, B, etc.)
4. Generates a `report.md` in `data/reports/` with grading evidence

---

## ğŸ”® Roadmap

- [ ] Support image-aware grading (diagrams, plots in PDFs)
- [ ] LMS integration (Canvas, Moodle)
- [ ] Multi-rubric & peer grading support
- [ ] Detailed analytics dashboard for instructors

---

## ğŸ¤ Contributing

PRs are welcome! Fork the repo and submit a pull request ğŸš€

---

## ğŸ“œ License

MIT License Â© 2025 Dhruv Jore
